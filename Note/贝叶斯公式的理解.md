
## **1. 贝叶斯方法**

### **1.1 贝叶斯方法的提出**

- 概率派:把需要推断的参数$\Theta$看做是**固定的未知常数**，即概率虽然是未知的，但最起码是确定的一个值，同时，**样本X是随机的**，所以频率派**重点研究样本空间**，大部分的概率计算都是针对样本X的分布
- 贝叶斯派：认为$\theta$是**随机变量**，而样本是**固定的**。由于样本固定，所以他们的研究重点是**参数$\theta$的分布**
  
  贝叶斯派既然把θ看做是一个随机变量，所以要计算θ的分布，便得事先知道**θ的无条件分布**，即在有样本之前（或观察到X之前），θ有着怎样的分布呢？

    >   比如往台球桌上扔一个球，这个球落会落在何处呢？如果是不偏不倚的把球抛出去，那么此球落在台球桌上的任一位置都有着相同的机会，即球落在台球桌上某一位置的概率服从均匀分布。这种**在实验之前定下的属于基本前提性质的分布称为先验分布，或的无条件分布。**

    至此，贝叶斯及贝叶斯派提出了一个思考问题的固定模式:

    > 先验分布 π(θ)+ 样本信息χ ⇒ 后验分布π(θ|x)

    上面的式子意味着新观察到的样本信息将会修改人们以前对事物的认知。得到新的样本信息之前，人们对的认知是先验分布 π(θ)，在得到新的样本信息后χ，人们对θ的认知为π(θ|x)。（基于x的后验分布）

    先验信息一般来源于经验和历史资料。比如夏季平均每周下雨一次，那么我们估计夏季的降雨概率为1/7。

    后验分布π(θ|x)一般也认为是在给定样本χ的情况下θ的条件分布，而使π(θ|x)达到最大的值 $\theta_{M,D}$ 称为最大后验估计，类似于经典统计学中的极大似然估计。

    综合起来看，则好比是人类刚开始时对大自然只有少得可怜的先验知识，但随着不断是观察、实验获得更多的样本、结果，使得人们对自然界的规律摸得越来越透彻。所以，贝叶斯方法既符合人们日常生活的思考方式，也符合人们认识自然的规律，经过不断的发展，最终占据统计学领域的半壁江山，与经典统计学分庭抗礼。


### **1.2 贝叶斯定理**
  - **条件概率**是事件A在另外一个事件B已经发生条件下的发生概率。条件概率表示为P(A|B)，读作“在B条件下A的概率”。
  - **联合概率**表示两个事件共同发生的概率。A与B的联合概率表示为$P(A\bigcap B)$ 或 $P(A,B)$
  - **边缘概率（先验概率）** 是某个事件发生的概率。边缘概率是这样得到的：在联合概率中，把最终结果中那些不需要的事件通过合并成它们的全概率，而消去它们（对离散随机变量用求和得全概率，对连续随机变量用积分得全概率），这称为边缘化（marginalization），比如A的边缘概率表示为$P(A)$，B的边缘概率表示为$P(B)$。 

  考虑如下问题：$P(A|B)$是在B发生的情况下，A发生的可能性。
  1. 首先，事件B发生之前，我们对事件A的发生有一个基本的概率判断，称为**A的先验概率**，用P(A)表示；
  2. 其次，事件B发生之后，我们对事件A的发生概率重新评估，称为**A的后验概率**，用P(A|B)表示；
  3. 类似的，事件A发生之前，我们对事件B的发生有一个基本的概率判断，称为**B的先验概率**，用P(B)表示；
  4. 同样，事件A发生之后，我们对事件B的发生概率重新评估，称为**B的后验概率**，用P(B|A)表示；

  于是有下述贝叶斯公式：
  > $P(A|B)=\frac{P(B|A)P(A)}{P(B)}$

  上述公式的推导其实非常简单，就是从条件概率推出。

  根据条件概率的定义，在事件B发生的条件下事件A发生的概率是：$P(A|B)=\frac{P(A\bigcap B)}{P(B)}$

  同样地，在事件A发生的条件下事件B发生的概率是：$P(B|A)=\frac{P(A\bigcap B)}{P(A)}$

  那么我们有$P(A \bigcap B) = P(B|A) \times P(A)$

  则有A的后验概率为：
  > $P(A|B)=\frac{P(A\bigcap B)}{P(B)} = \frac{P(B|A) \times P(A)}{P(B)}$


### **1.3 应用：拼写检查**

   经常在网上搜索东西的朋友知道，当你不小心输入一个不存在的单词时，搜索引擎会提示你是不是要输入某一个正确的单词，比如当你在Google中输入“Julw”时，系统会提示你是不是要搜索“July”。   这叫做拼写检查。
   
   根据谷歌一员工写的文章显示，Google的拼写检查基于贝叶斯方法。下面我们就来看看，怎么利用贝叶斯方法，实现"拼写检查"的功能。
   
   用户输入一个单词时，可能拼写正确，也可能拼写错误。如果把拼写正确的情况记做c（代表correct），输错为w（代表wrong）。那么"拼写检查"要做的事情就是：在发生w的情况下，试图推断出c。即已知w，然后在若干个备选方案中，找出可能性最大的那个c，也就是求的最大值。
    而根据贝叶斯定理，有：
    
  > $P(c|w)=\frac{P(w|c) \times P(c)}{P(w)}$
    
  由于对于所有备选的c来说，对应的都是同一个w，所以它们的P(w)是相同的，因此我们只要最大化$P(w|c) \times P(c)$  即可。其中：
  - $P(c)$表示某个正确的词的出现"概率"，它可以用"频率"代替。如果我们有一个足够大的文本库，那么这个文本库中每个单词的出现频率，就相当于它的发生概率。某个词的出现频率越高，$P(c)$就越大。
  
  - $P(w|c)$表示在试图拼写c的情况下，出现拼写错误w的概率。为了简化问题，假定两个单词在字形上越接近，就有越可能拼错，$P(w|c)$就越大。举例来说，相差一个字母的拼法，就比相差两个字母的拼法，发生概率更高。你想拼写单词$July$，那么错误拼成$Julw$（相差一个字母）的可能性，就比拼成$Jullw$高（相差两个字母）。
  
所以，我们只要找到与输入单词在字形上最相近的那些词，再在其中挑出出现频率最高的一个，就能实现的最大值。

[参考:从贝叶斯方法谈到贝叶斯网络](https://blog.csdn.net/zdy0_2004/article/details/41096141)

