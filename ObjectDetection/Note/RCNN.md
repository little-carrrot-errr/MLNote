
RCNN模型由下面三个部分组成：
1. 生成内容独立的region proposals(下面就用提案区域、区域代替)。这些区域将作为我们模型重要的候选检测部分。
2. 一个大的卷积网络对每一个区域生成固定大小的特征向量。
3. 一组用以特征分类的线性SVM

## **2.1 模型设计**
---

**Region proposals**

在众多region proposal的方法中，作者采用了 **selective search**

**Feature extraction**
利用Caffe框架实现的CNN网络提取4096维度的特征，其中输入图片为227 $\times$ 227 RGB 图片，通过五层的卷积网络以及两层全连接网络，并使用前向反馈计算。

为了使得得到的region proposal 能满足227 $\times$ 227 的大小，作者尝试了两种办法：

1. 各向异性缩放

    这种方法很简单，就是不管图片的长宽比例，管它是否扭曲，进行缩放就是了，全部缩放到CNN输入的大小227*227，如下图(D)所示；

2. 各向同性缩放
   1. 直接在原始图片中，把bounding box的边界进行扩展延伸成正方形，然后再进行裁剪；如果已经延伸到了原始图片的外边界，那么就用bounding box中的颜色均值填充；如下图(B)所示;
   2. 先把bounding box图片裁剪出来，然后用固定的背景颜色填充成正方形图片(背景颜色也是采用bounding box的像素颜色均值),如下图(C)所示;
    
    ![](https://img-blog.csdn.net/20160315191333440?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

对于上面的异性、同性缩放，文献还有个padding处理，上面的示意图中第1、3行就是结合了padding=0,第2、4行结果图采用padding=16的结果。经过最后的试验，作者发现采用各向异性缩放、padding=16的精度最高。

## **2.2 测试过程**
---

在测试过程中，作者使用selective search 生成2000个region proposals。将这些proposal进行异性缩放，并利用前向传播传向网络得到特征向量。最后，对于每一种类型，利用生成的特征向量都训练一个SVM。对所有的regions给定一个分数，利用greedy non-maximun suppression（贪婪非极大值抑制）对每个类型单独的处理。

运行过程中，作者提出有两个性质使得模型检测高效：1. 所有的CNN共享所有类别的参数；2.通过CNN 得到的特征向量是低维的。

共享参数的优点是，在所有类别上均摊销了用于计算region proposal和特征feature的时间（GPU上为13s /图像，CPU上为53s /图像）。唯一针对单个类的计算是 特征与SVM参数与非极大抑制的点积。在实际训练中对一个图片所有的点积都被batched为一个单独的矩阵$\times$矩阵的点积。

## **2.3 训练**
---

### **1. Supervised pre-training**
我们在一个大型辅助数据集(ILSVRC 2012分类)上对cnn进行了区分性的预训练，只使用图像级注解(边框标签不能用于此数据)。

### **2. Domain-specific fine-tuning**
为了使cnn适应新的任务(检测)和新区域(warped proposal Windows)，我们仅使用warped region proposal继续对cnn参数进行随机梯度下降(Sgd)训练。假设要检测的物体类别有N类，那么我们就需要把上面预训练阶段的CNN模型的最后一层给替换掉，替换成N+1个输出的神经元(加1，表示还有一个背景)，然后这一层直接采用参数随机初始化的方法，其它网络层的参数不变；接着就可以开始继续SGD训练了。**在这个过程中IoU被设置为0.5**，大于0.5则作为正样本，小于就作为负样本。开始的时候，SGD学习率选择0.001，在每次训练的时候，我们batch size大小选择128，其中32个事正样本、96个事负样本（正负样本的定义前面已经提过，不再解释）。

[以上部分参考；原文链接](https://blog.csdn.net/hjimce/article/details/50187029)

### **3. 物体类别分类-SVM训练阶段**


**问题： CNN训练的时候，本来就是对bounding box的物体进行识别分类训练，是一个端到端的任务，在训练的时候最后一层softmax就是分类层，那么为什么作者闲着没事干要先用CNN做特征提取（提取fc7层数据），然后再把提取的特征用于训练svm分类器**？这个是因为svm训练和cnn训练过程的正负样本定义方式各有不同，导致最后采用CNN softmax输出比采用svm精度还低。

事情是这样的，cnn在训练的时候，对训练数据做了比较宽松的标注，比如一个bounding box可能只包含物体的一部分，那么我也把它标注为正样本，用于训练cnn；采用这个方法的主要原因在于因为CNN容易过拟合，所以需要大量的训练数据，所以在CNN训练阶段我们是对Bounding box的位置限制条件限制的比较松(IOU只要大于0.5都被标注为正样本了)；

然而svm训练的时候，因为svm适用于少样本训练，所以对于训练样本数据的IOU要求比较严格，我们只有当bounding box把整个物体都包含进去了，我们才把它标注为物体类别，然后训练svm。

[以上原文链接](https://blog.csdn.net/hjimce/article/details/50187029)


考虑训练二进制分类器来检测汽车：很明显，一个紧紧包围汽车的图像区域应该是一个积极的例子。同样，很明显，一个背景区域，它与汽车无关，应该是一个负面的例子。不太清楚的是如何给部分重叠的区域贴上标签。我们用IOU重叠阈值来解决这个问题，**低于这个阈值的区域被定义为负数**。最终我们选定的重叠阈值为0.3，是在验证集{0,0.1，...,0.5}上由网格搜索选择的。0使得精度下降4%，0.5使得精度下降5%。

因此，提取特征并应用训练标签后，我们将为每个类优化一个线性SVM。 由于训练数据太大而无法存储在内存中，因此我们采用标准的严格negative mining method[17，37]。 它能帮助快速收敛，实际上，仅对所有图像进行一次遍历之后，mAP就会停止增加。