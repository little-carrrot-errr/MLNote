# **Application of CNNs**

## **Image Classification图像分类**
CNNs在图像分类中的应用已经很长时间了[168-171]。与其他方法相比，由于CNN在组合特征和分类学习中的能力，它可以在大规模数据集上获得更好的准确性[8,9,172]。大规模图像分类的突破出现在2012年。Krizhevsky等人[8]开发AlexNet，并在2012年ILSVRC中取得最佳成绩。在AlexNet成功之后，许多方法通过缩小过滤器大小[11]或扩大网络深度[9，10]使得CNN在分类精度上取得了显著的提高。

在多标签分类中，构建一个结构化的分类器是一个常用的图像分类的方法[173]。
- [174]的工作是在cnn中引入类别层次的最早尝试之一，其中提出了一种基于树优先（**tree-based**）的区分转移学习方法（**discriminative transfer learning**）。他们使用一种类的层次结构在相关类之间共享信息，以提高训练样例少的类别的性能。
- Wang等人[175]建立一个树结构来学习细粒度特征用于子类别识别
- Xiao等人[176]提出了一种训练方法，该方法不仅可以逐步增长网络，而且可以分层增长网络。首先使用粗分类CNN分类器将容易区分的类彼此分离，然后将那些难以分类的类路由到下游的精细类别分类器，以便进一步的预测。该体系结构遵循粗糙到精细的分类模式，可以以可承受的复杂度增加为代价，获得较低的误差。

子类别（子标签）分类是另一类发展迅速的图像识别的领域。已经有一些细粒度的图像数据集(如鸟类[178]、狗[179]、汽车[180]和植物[181])。使用对象部分信息（object part information）有利于细粒度分类[182]。一般情况下，通过定位物体的重要部分并以区分度大的方式来表示它们的外形，可以训练的提高精度。
- Branson等[183]提出了一种检测局部的方法，并从多姿态归一化区域（**multiple pose-normalized regions**）提取CNN特征。他们还建立了一个模型，将低层特征层与姿态规范化提取例程相结合，并将更高级别的特征层与**未对齐图像**([image alignment](https://blog.csdn.net/h763247747/article/details/100862863))特征结合起来，以改进分类的准确性。
- Zhang等人【184】提出了一种基于局部的R-CNN方法，该方法可以学习全目标和局部检测器。他们使用 **selective search**（[参考](https://www.cnblogs.com/zyly/p/9259392.html)）来生成局部区域（**part proposal**），并使用非参数几何约束 **non-parametric geometric constraints** (采用了几何约束，将块检测的结果约束在物体检测的一定范围内)来获得更加准确地局部定位。[参考](https://blog.csdn.net/sheng_ai/article/details/41806341)
- Lin等人[186]将局部定位、图像对齐以及图像分类组合到一个识别系统中，其名为 **Deep LAC**。系统由**三个子网组成**：
  - 定位子网用于估计局部位置，输出为框的左上角及右下角点的坐标
  - 对齐子网络接收部件定位结果，执行模板对齐，产生姿态对齐的部件图像 [187],对齐子网络进行平移、缩放、旋转等操作用于姿态对齐区域的生成。同时，该子网络还负责反向传播过程中分类及定位结果的桥接作用。
  - 分类子网络以位姿对齐部分图像作为输入来预测类别标签。
- 他们还提出了一个**阀门连接函数 value linkage function**来连接子网络，并使它们在训练和测试中作为一个整体。

需要注意的是，上述所有方法都是利用部分注释信息进行监督培训的。然而，这些注释并不容易收集，而且这些系统很难扩展和以及难以处理许多类型的细粒度类。为了避免这一问题，一些研究人员开始研究在没有监督的情况下找到局部的部分或区域的问题。

[见微知著——细粒度图像分析进展综述 ](https://www.sohu.com/a/134764420_473283)
- Krause等人[188]将局部学习特征表示的集合用于细粒分类，他们使用**共同分割和对齐** **co-segmentation and alignment** 来生成局部，然后比较各个部分的不同，合并类似的局域。在他们最新的论文中【189】，他们将共分割和对齐结合在一个区分性的混合模型（**discriminative mixture**）中，以生成有利于细粒度分类的部件。
- Zhang等人[190]使用**无监督的选择性搜索生成目标proposal**，然后从多尺度生成的局部proposals中选择有用的部分
- Xiao等人[191]在cnn中应用视觉注意机制（**visual attention**）进行细粒度分类。他们的分类器主要分为是哪个阶段：1. bottom-up attention：获取多个候选框；2. object-level top-down机制选择某个物体的相关的patches；3. 在part level top-down机制中定位区分不同的部分：
![](/img/Two&#32;Level&#32;Attention&#32;Model.png)

   - 将这三个结构结合进行训练得到的网络对于查找前景对象或对象部分，并提取识别特征有很大帮助。
 - 林等人[192]提出了一种用于**细粒度图像分类的双线性模型**。识别结构由两个特征提取器组成。两个特征提取器的输出在图像的每个位置使用外部乘积进行相乘，并汇集以获得 **an image descriptor**

---
## **Object Tracking(对象跟踪)**
对象跟踪的成功很大程度上依赖于目标外观的表示对几个挑战（如视点变化  **view point changes**、光照变化 **illumination changes** 和闭塞**occlusions**）的鲁棒性如何[213] –215]。有许多尝试将CNN应用于对象追踪中。
- Fan等人【216】将CNN作为基础学习器。它学习一个单独的特定于类的网络来跟踪对象。在【216】中，作者利用**位移偏差结构shift-variant architecture**设计了一个CNN tracker/CNN跟踪器。这种架构起着关键的作用，它将CNN模型从检测器转变为跟踪器。这些功能是在离线培训期间学习的。 与仅提取局部空间结构的传统跟踪器不同，此基于CNN的跟踪方法通过考虑两个连续帧的图像来提取空间和时间结构。由于时间信息中的大信号倾向于出现在正在移动的物体附近，因此时间结构为跟踪提供了原始速度信号。
- Li等人【217】提出了一个目标特定的cnn用于目标跟踪，其中cnn在跟踪过程中通过在线获得的新示例进行增量训练。它们使用多个CNNs的候选池作为目标对象的不同实例的数据驱动模型。个体上，每个CNN维护一组特定的kernels，可以利用低级的线索（low-level cues）很好的将物体从他们周围环境中区分出来。这些核在对应的CNN初始化时仅用一个实体训练，之后这些核将会用过在线的方式在每一帧被更新。
  
    与过去对所有的对象训练一个复杂而有效的CNN模型不同，他们在具有实时更新机制的框架内，在CNN中使用一些相对较少的filters。给定一帧，池中最好的CNN将会被选择出来作为判别对象假设。最高分的假设将会被设置为当前物体的检测窗口，被选择的模型使用热启动反向传播重新训练，从而优化结构损失函数。
-  在[218]中，提出了一种cnn目标跟踪方法，以解决目标跟踪问题中手工特征和浅分类器结构的局限性。识别特征首先通过CNN自动学习。为了减轻在模型更新中tracker的**drifting problem**，跟踪器利用初始帧的物体标记信息以及在新获得的观测的图像的 **ground truth**外观信息。使用启发式模式判断是否更新对象外观模型。
- Hong等人[219]提出了一种基于预先训练的cnn的视觉跟踪算法，其中网络最初是为大规模图像分类而训练的，并且学习到的表示转化为描述的物体。在cnn隐藏层的顶部，他们添加了一个在线支持向量机的附加层，用于区别学习目标及其背景。通过反向投影相关的信息到输入图像空间，模型通过SVM的学习来计算特定目标的显著图 **saliency map**。他们利用目标特定的显着性图来获取生成的目标外观模型，并在了解目标空间配置的情况下进行跟踪。

--- 
## **Pose Estimation姿态估计**